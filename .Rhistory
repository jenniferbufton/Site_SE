train_d <- d[train_index,]
test_d <- d[-train_index,]
# testing distribution
#table((d$Over_Target))
#prop.table(table(d$Over_Target))
#prop.table(table(train_d$Over_Target))
#prop.table(table(test_d$Over_Target))
#knn
train_d_no_class <- train_d[,-9] # no target variable (Over_Target in this case)
test_d_no_class <- test_d[,-9] # no target variable (Over_Target in this case)
train_d_labels <- train_d[,9] # Only target variable (Over_Target in this case)
# sqrt(nrow(d)) # find square root of nrows
# 8 predictors in this model
d_test_pred <- knn(train = train_d_no_class, test = test_d_no_class,
cl = train_d_labels, k = 27)
#evaluation
test_d$pred <- d_test_pred # add new prediction column
test_d$correct <- 'n'
test_d$correct[test_d$Over_Target == test_d$pred] <- 'y' # Add another column which shows if correct
kable(table(test_d$correct)) # 29/30 correct
kable(prop.table(table(test_d$correct))) #97% correct
CrossTable(x = test_d$Over_Target, y = d_test_pred,
prop.chisq=FALSE)
#sampling method 2, using data partition function from caret package. It attempts to retain similar distributions of species across the train and test datasets. Times argument is number of partitions to create , List defines how you want the multiple partitions stored (list or matrix)
# more info on this method here https://topepo.github.io/caret/data-splitting.html
train_index <- createDataPartition(d$Over_Target, p = 0.8, times=1, list = FALSE) # from caret package. !st argument is dependent varaible, p = split, times = number it runs, list = false if 1 tmes
train_d <- d[train_index,]
test_d <- d[-train_index,]
# testing distribution
#table((d$Over_Target))
#prop.table(table(d$Over_Target))
#prop.table(table(train_d$Over_Target))
#prop.table(table(test_d$Over_Target))
#knn
train_d_no_class <- train_d[,-9] # no target variable (Over_Target in this case)
test_d_no_class <- test_d[,-9] # no target variable (Over_Target in this case)
train_d_labels <- train_d[,9] # Only target variable (Over_Target in this case)
# sqrt(nrow(d)) # find square root of nrows
# 8 predictors in this model
d_test_pred <- knn(train = train_d_no_class, test = test_d_no_class,
cl = train_d_labels, k = 27)
#evaluation
test_d$pred <- d_test_pred # add new prediction column
test_d$correct <- 'Incorrect'
test_d$correct[test_d$Over_Target == test_d$pred] <- 'Correct' # Add another column which shows if correct
#kable(table(test_d$correct))
kable(prop.table(table(test_d$correct)), col.names = c("Correct?","Proportion"))%>%
kable_styling(bootstrap_options = "bordered",
full_width = FALSE)
#kable(CrossTable(x = test_d$Over_Target, y = d_test_pred,
# prop.chisq=FALSE))
kable(CrossTable(x = test_d$Over_Target, y = d_test_pred,
prop.chisq=FALSE))
CrossTable(x = test_d$Over_Target, y = d_test_pred,
prop.chisq=FALSE)
# looks good! Could test different k values and normalising to see if improvements could be made. Could also cross validate by running again with a different random sample of train and test
library(httr)
?GET
library(httr)
library(jsonlite)
username <- "jennifer.bufton@sportengland.org"
password <- "3m1xKUfas8tmTgjQ29AKSHPGWburMXZliUd67-ZD"
base = "https://api.companieshouse.gov.uk/search/companies/Sport+England"
df <- GET(base,
authenticate("user", "pass", type = "basic"),
add_headers(auth_appkey = password))
df
jsonlite::parse_json(df)
authenticate(username, password, type = "basic")
jsonlite::parse_json(df)
#username <- "jennifer.bufton@sportengland.org"
username <- "Sport England"
password <- "3m1xKUfas8tmTgjQ29AKSHPGWburMXZliUd67-ZD"
base = "https://api.companieshouse.gov.uk/search/companies/Sport+England"
df <- GET(base,
df
jsonlite::parse_json(df)
jsonlite::parse_json(df)
username <- "3m1xKUfas8tmTgjQ29AKSHPGWburMXZliUd67-ZD"
password <- ""
base = "https://api.companieshouse.gov.uk/search/companies/Sport+England"
df <- GET(base,
jsonlite::parse_json(df)
base = "3m1xKUfas8tmTgjQ29AKSHPGWburMXZliUd67-ZD:https://api.companieshouse.gov.uk/search/companies/Sport+England"
df <- GET(base)
jsonlite::parse_json(df)
df <- GET(base, authenticate(user = username, password = password))
jsonlite::parse_json(df)
jsonlite::parse_json(df)
base = "https://api.companieshouse.gov.uk/search/companies?q=Football+Association"
username <- "3m1xKUfas8tmTgjQ29AKSHPGWburMXZliUd67-ZD"
password <- ""
df <- GET(base, authenticate(user = username, password = password))
jsonlite::parse_json(df)
jsonlite::fromJSON(df)
df
jsonlite::read_json(df)
df <- jsonlite::parse_json(df)
install.packages('sf')
setwd("C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/LAD")
library(sf)
input.file <- system.file('LAD.JSON')
new_cells <- calculate_grid(shape = input.file,
grid_type = "hexagonal", seed = 1)
input.file <- sf::gdal_read('LAD.JSON')
new_cells <- calculate_grid(shape = input.file,
grid_type = "hexagonal", seed = 1)
library(geogrid)
new_cells <- calculate_grid(shape = input.file,
grid_type = "hexagonal", seed = 1)
install.packages('sp')
install.packages("sp")
library(sp)
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(ggplot2)
library(scales)
library(plyr)
library(dplyr)
library(tidyr)
library(extrafont)
library(rgdal)
library(viridis)
### read in data to append
df <- read.csv('C:/Users/jenniferb/OneDrive - Sport England/Power BI/Active Lives Survey/Gender_May1819_LA_CC_Regv2.csv')
df <- df %>%
select('lad19cd', 'Male.Active')
range(df$Male.Active)
#import shapefile
setwd("C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/LAD/Local_Authority_Districts_April_2019_Boundaries_UK_BUC")
map1 <- readOGR(dsn = ".", layer = "Local_Authority_Districts_April_2019_Boundaries_UK_BUC", verbose = FALSE)
summary(map1) # see if projections used
HexPts <-spsample(map1, type="hexagonal", cellsize=1000)
## map without distortion
map1@data$id <- rownames(map1@data)
map1@data   <- join(map1@data, df, by="lad19cd")
map.clean     <- fortify(map1)
map.clean     <- join(map.clean,map1@data, by="id")
map.clean <- map.clean[grep("E", map.clean$lad19cd),] # England only
map.clean <- map.clean[, !duplicated(colnames(map.clean))] # remove dupe cols
HexPols <- HexPoints2SpatialPolygons(HexPts)
plot(HexPols)
setwd("C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/LAD/Local_Authority_Districts_April_2019_Boundaries_UK_BUC")
file.shp <- "C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/LAD/Local_Authority_Districts_April_2019_Boundaries_UK_BUC/Local_Authority_Districts_April_2019_Boundaries_UK_BUC.shp"
install.packages('hexmapr')
install.packages('gridExtra')
install.packages("gridExtra")
install.packages('gridExtra')
library("broom") # to put shapefile into a dataframe format
install.packages('broom')
install.packages("broom")
file.shp <- "C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/LAD/Local_Authority_Districts_April_2019_Boundaries_UK_BUC/Local_Authority_Districts_April_2019_Boundaries_UK_BUC.shp"
LAD_shp <- read_polygons(file.shp)
df <- read.csv('C:/Users/jenniferb/OneDrive - Sport England/Power BI/Active Lives Survey/Gender_May1819_LA_CC_Regv2.csv')
df <- df %>%
select('lad19cd', 'Male.Active')
library(dplyr)
df <- df %>%
select('lad19cd', 'Male.Active')
LAD_shp_data <- sp::merge(LAD_shp,
df,
by.x="lad19cd",
by.y="lad19cd",
duplicateGeoms=T,
all.x=F)
LAD_shp <- read_polygons(file.shp)
install_github("sassalley/hexmapr") # install hexmapr if not installed already
?read_polygon
??read_polygon
library(geogrid)
LAD_shp <- read_polygons(file.shp)
plot(LAD_shp)
df <- df %>%
select('lad19cd', 'Male.Active')
LAD_shp_data <- sp::merge(LAD_shp,
df,
by.x="lad19cd",
by.y="lad19cd",
duplicateGeoms=T,
all.x=F)
clean <- function(shape){
shape@data$id = rownames(shape@data)
shape.points = tidy(shape, region="id")
shape.df = inner_join(shape.points, shape@data, by="id")
}
# Apply function to shapefile
LAD_shp_data_tidy <- clean(LAD_shp_data)
library("tidyverse")#; theme_set(theme_bw())
# Apply function to shapefile
LAD_shp_data_tidy <- clean(LAD_shp_data)
library("broom") # to put shapefile into a dataframe format
library("devtools") # to enable installing from github
install.packages('devtools')
# Apply function to shapefile
LAD_shp_data_tidy <- clean(LAD_shp_data)
?tidy
??tidy
library("broom") # to put shapefile into a dataframe format
clean <- function(shape){
shape@data$id = rownames(shape@data)
shape.points = tidy(shape, region="id")
shape.df = inner_join(shape.points, shape@data, by="id")
}
# Apply function to shapefile
LAD_shp_data_tidy <- clean(LAD_shp_data)
?inner_join
library(dplyr)
clean <- function(shape){
shape@data$id = rownames(shape@data)
shape.points = tidy(shape, region="id")
shape.df = inner_join(shape.points, shape@data, by="id")
}
# Apply function to shapefile
LAD_shp_data_tidy <- clean(LAD_shp_data)
# plot the map
(plot_1 <- ggplot(LAD_shp_data_tidy, aes(long.x,
lat.x,
fill=Value,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma") +
coord_equal() + theme_void())
library("tidyverse")#; theme_set(theme_bw())
# plot the map
(plot_1 <- ggplot(LAD_shp_data_tidy, aes(long.x,
lat.x,
fill=Value,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma") +
coord_equal() + theme_void())
library("viridis") # fancy colour palettes
# plot the map
(plot_1 <- ggplot(LAD_shp_data_tidy, aes(long.x,
lat.x,
fill=Value,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma") +
coord_equal() + theme_void())
# plot the map
(plot_1 <- ggplot(LAD_shp_data_tidy, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma") +
coord_equal() + theme_void())
par(mfrow=c(3,3), mar = c(0,0,2,0))
for (i in 1:9){
new_cells <-  calculate_cell_size(LAD_shp_data, LAD_shp_details,0.03, 'hexagonal', i)
plot(new_cells[[2]], main = paste("Seed",i, sep=" "))
}
#install_github("sassalley/hexmapr") # install hexmapr if not installed already
library("hexmap")
#install_github("sassalley/hexmapr") # install hexmapr if not installed already
library(hexbin)
LAD_shp_details <- get_shape_details(LAD_shp_data)
?get_shape_details
??get_shape_details
library(geogrid)
LAD_shp_details <- get_shape_details(LAD_shp_data)
LAD_shp_details <- calculate_grid(LAD_shp_data)
par(mfrow=c(3,3), mar = c(0,0,2,0))
for (i in 1:9){
new_cells <-  calculate_cell_size(LAD_shp_data, LAD_shp_details,0.03, 'hexagonal', i)
plot(new_cells[[2]], main = paste("Seed",i, sep=" "))
}
new_cells <-  calculate_grid(LAD_shp_data, LAD_shp_details,0.03, 'hexagonal', i)
new_cells <-  calculate_grid(LAD_shp_data, LAD_shp_details,0.3, 'hexagonal', i)
new_cells_hex <-  calculate_cell_size(LAD_shp_data, LAD_shp_details,0.03, 'hexagonal', 3)
new_cells_hex <-  calculate_grid(LAD_shp_data, LAD_shp_details,0.03, 'hexagonal', 3)
?calculate_grid
new_cells_hex <-  calculate_grid(shape = LAD_shp_data, LAD_shp_details,0.03, 'hexagonal')
new_cells_hex <-  calculate_grid(shape = LAD_shp_data, LAD_shp_details, 'hexagonal')
new_cells_hex <-  calculate_grid(shape = LAD_shp_data, learning_rate = 0.03, grid_type = c('hexagonal', "regular", seed = NULL)
resulthex <- assign_polygons(LAD_shp_data,new_cells_hex)
resulthex <- assign_polygons(LAD_shp_data,new_cells_hex)
new_cells_hex <-  calculate_grid(shape = LAD_shp_data, learning_rate = 0.03, grid_type = c('hexagonal', "regular", seed = NULL)
new_cells_hex <-  calculate_grid(shape = LAD_shp_data, learning_rate = 0.03, grid_type = c('hexagonal', "regular"), seed = NULL)
new_cells_hex <-  calculate_grid(shape = LAD_shp_data, learning_rate = 0.03, grid_type = c('hexagonal', "regular"), seed = NULL)
resulthex <- assign_polygons(LAD_shp_data,new_cells_hex)
resulthex <- assign_polygons(LAD_shp_data,new_cells_hex)
library("tidyverse")#; theme_set(theme_bw())
library("broom") # to put shapefile into a dataframe format
library("devtools") # to enable installing from github
install.packages('devtools')
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
library("tidyverse")#; theme_set(theme_bw())
library("broom") # to put shapefile into a dataframe format
library("devtools") # to enable installing from github
library("fingertipsR") # to access PHE fingertips data
#install_github("sassalley/hexmapr") # install hexmapr if not installed already
library(hexbin)
library("viridis") # fancy colour palettes
library("gridExtra") # to arrange multiple plots
library(geogrid)
file.shp <- "C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/LAD/Local_Authority_Districts_April_2019_Boundaries_UK_BUC/Local_Authority_Districts_April_2019_Boundaries_UK_BUC.shp"
LAD_shp <- read_polygons(file.shp)
LAD_shp <- sf::st_read(file.shp)
View(LAD_shp)
plot(LAD_shp)
df <- read.csv('C:/Users/jenniferb/OneDrive - Sport England/Power BI/Active Lives Survey/Gender_May1819_LA_CC_Regv2.csv')
df <- df %>%
select('lad19cd', 'Male.Active')
LAD_shp_data <- sp::merge(LAD_shp,
df,
by.x="lad19cd",
by.y="lad19cd",
duplicateGeoms=T,
all.x=F)
clean <- function(shape){
shape@data$id = rownames(shape@data)
shape.points = tidy(shape, region="id")
shape.df = inner_join(shape.points, shape@data, by="id")
}
# Apply function to shapefile
LAD_shp_data_tidy <- clean(LAD_shp_data)
LAD_shp <- read_polygons(file.shp)
plot(LAD_shp)
df <- read.csv('C:/Users/jenniferb/OneDrive - Sport England/Power BI/Active Lives Survey/Gender_May1819_LA_CC_Regv2.csv')
df <- df %>%
select('lad19cd', 'Male.Active')
LAD_shp_data <- sp::merge(LAD_shp,
df,
by.x="lad19cd",
by.y="lad19cd",
duplicateGeoms=T,
all.x=F)
clean <- function(shape){
shape@data$id = rownames(shape@data)
shape.points = tidy(shape, region="id")
shape.df = inner_join(shape.points, shape@data, by="id")
}
# Apply function to shapefile
LAD_shp_data_tidy <- clean(LAD_shp_data)
LAD_shp_data_tidy - LAD_shp_data_tidy[grep("E", map.clean$lad19cd),]
LAD_shp_data_tidy - LAD_shp_data_tidy[grep("E",  LAD_shp_data_tidy$lad19cd),]
head(LAD_shp_data_tidy$lad19cd)
LAD_shp_data_tidy <- LAD_shp_data_tidy[grep("E", LAD_shp_data_tidy$lad19cd),]
plot(LAD_shp_data_tidy)
# plot the map
(plot_1 <- ggplot(LAD_shp_data_tidy, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma") +
coord_equal() + theme_void())
LAD_shp_details <- calculate_grid(LAD_shp_data)
# test
par(mfrow=c(3,3), mar = c(0,0,2,0))
for (i in 1:9){
new_cells <-  calculate_grid(shape = LAD_shp_data, learning_rate = 0.03, grid_type = c('hexagonal', "regular"), seed = i)
plot(new_cells[[2]], main = paste("Seed",i, sep=" "))
}
new_cells_hex <-  calculate_grid(shape = LAD_shp_data, learning_rate = 0.03, grid_type = c('hexagonal', "regular"), seed = 1)
resulthex <- assign_polygons(LAD_shp_data,new_cells_hex)
# generate plot
plot_2 <- ggplot(resulthex, aes(long.x,
lat.x,
fill=Value,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma") +
coord_equal() + theme_void()
# arrange plot with comparison to the original
grid.arrange(plot_1, plot_2, nrow=1, ncol=2)
# generate plot
plot_2 <- ggplot(resulthex, aes(long,
lat,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma") +
coord_equal() + theme_void()
# arrange plot with comparison to the original
grid.arrange(plot_1, plot_2, nrow=1, ncol=2)
resulthex <- clean(resulthex)
# generate plot
plot_2 <- ggplot(resulthex, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma") +
coord_equal() + theme_void()
# arrange plot with comparison to the original
grid.arrange(plot_1, plot_2, nrow=1, ncol=2)
# generate plot
plot_2 <- ggplot(resulthex, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma", name = "Male Active") +
coord_equal() + theme_void() +
theme(element_text(family = "Poppins"))
# generate plot
plot_2 <- ggplot(resulthex, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma", name = "Male Active") +
coord_equal() + theme_void() +
theme(text = element_text(family = "Poppins"))
# arrange plot with comparison to the original
grid.arrange(plot_1, plot_2, nrow=1, ncol=2)
write.csv('HexMap_England.csv')
setwd("C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data")
colnames(resulthex)
resulthex.save <- resulthex[,-22]
write.csv(resulthex.save, 'HexMap_England.csv')
write.csv(resulthex, 'HexMap_England_Active.Males.csv')
# generate plot
plot_2 <- ggplot(resulthex, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma", name = "Male Active", labels = percent(0.1*0:9)) +
coord_equal() + theme_void() +
theme(text = element_text(family = "Poppins"))
library(scales)
# generate plot
plot_2 <- ggplot(resulthex, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma", name = "Male Active", labels = percent(0.1*0:9)) +
coord_equal() + theme_void() +
theme(text = element_text(family = "Poppins"))
# arrange plot with comparison to the original
grid.arrange(plot_1, plot_2, nrow=1, ncol=2)
# generate plot
plot_2 <- ggplot(resulthex, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma", name = "Male Active", labels = percent()) +
coord_equal() + theme_void() +
theme(text = element_text(family = "Poppins"))
# generate plot
plot_2 <- ggplot(resulthex, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma", name = "Male Active", breaks = 0.1*0:9, labels = percent(0.1*0:9)) +
coord_equal() + theme_void() +
theme(text = element_text(family = "Poppins"))
# arrange plot with comparison to the original
grid.arrange(plot_1, plot_2, nrow=1, ncol=2)
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(extrafont)
library(viridis)
library(viridisLite)
library(scales)
### read in data to append
resulthex <- read.csv('C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/HexMap_England_Active.Males.csv')
knitr::opts_chunk$set(echo = TRUE)
### read in data to append
resulthex <- read.csv('C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/HexMap_England_Active.Males.csv')
# load packages
library(ggplot2)
library(extrafont)
library(viridisLite)
library(scales)
ggplot(resulthex, aes(long.x,
lat.x,
fill=Male.Active,
group=group)) +
geom_polygon(col="white") +
scale_fill_viridis(option="magma", name = "Male Active", breaks = 0.1*0:9, labels = percent(0.1*0:9)) +
coord_equal() + theme_void() +
theme(text = element_text(family = "Poppins"))
install.packages('rlang')
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
### read in data to append
resulthex <- read.csv('C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/HexMap_England_Active.Males.csv')
kable(resulthex[1:5,]) %>%
kable_styling(bootstrap_options = "bordered",
full_width = FALSE)
knitr::opts_chunk$set(include = FALSE)
library(kableExtra)
### read in data to append
resulthex <- read.csv('C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/HexMap_England_Active.Males.csv')
file.shp <- "C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/LAD/Local_Authority_Districts_April_2019_Boundaries_UK_BUC/Local_Authority_Districts_April_2019_Boundaries_UK_BUC.shp"
library("tidyverse")# for ggplot
library("broom") # to put shapefile into a dataframe format
library("devtools") # to enable installing from github
library("fingertipsR") # to access PHE fingertips data
library("hexbin")
library("viridis") # fancy colour palettes
library("gridExtra") # to arrange multiple plots
library("geogrid")
library("extrafont") # for bespoke font
library("scales") # for ggplot
knitr::opts_chunk$set(include = FALSE)
library(kableExtra)
### read in data to append
resulthex <- read.csv('C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/HexMap_England_Active.Males.csv')
file.shp <- "C:/Users/jenniferb/OneDrive - Sport England/GitHub/Geographical Data/LAD/Local_Authority_Districts_April_2019_Boundaries_UK_BUC/Local_Authority_Districts_April_2019_Boundaries_UK_BUC.shp"
